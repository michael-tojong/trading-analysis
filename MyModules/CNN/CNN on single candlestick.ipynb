{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: The finance module has been deprecated in mpl 2.0 and will be removed in mpl 2.2. Please use the module mpl_finance instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.finance as finplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from os import listdir\n",
    "import datetime\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'dukascopy - EURUSD_Candlestick_4_Hour_BID_31.12.2015-30.12.2016.csv',\n",
    "                 parse_dates=[0], index_col=0, date_parser=lambda d: pd.datetime.strptime(d[:13], '%d.%m.%Y %H'))\n",
    "\n",
    "df_window = df.iloc[40:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(r'y candles.csv',\n",
    "                parse_dates=[0], index_col=0, date_parser=lambda d: pd.datetime.strptime(d[:13], '%Y-%m-%d %H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = [d in y.index for d in df_window.index]\n",
    "df_window = df_window.loc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gmt time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-08 00:00:00</th>\n",
       "      <td>1.10634</td>\n",
       "      <td>1.10815</td>\n",
       "      <td>1.10622</td>\n",
       "      <td>1.10814</td>\n",
       "      <td>17745.2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-08 04:00:00</th>\n",
       "      <td>1.10816</td>\n",
       "      <td>1.10899</td>\n",
       "      <td>1.10722</td>\n",
       "      <td>1.10764</td>\n",
       "      <td>28404.7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-08 08:00:00</th>\n",
       "      <td>1.10764</td>\n",
       "      <td>1.10811</td>\n",
       "      <td>1.10572</td>\n",
       "      <td>1.10627</td>\n",
       "      <td>37149.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-08 12:00:00</th>\n",
       "      <td>1.10626</td>\n",
       "      <td>1.11201</td>\n",
       "      <td>1.10018</td>\n",
       "      <td>1.10360</td>\n",
       "      <td>78897.1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-08 16:00:00</th>\n",
       "      <td>1.10361</td>\n",
       "      <td>1.10594</td>\n",
       "      <td>1.10352</td>\n",
       "      <td>1.10515</td>\n",
       "      <td>26419.8901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Open     High      Low    Close      Volume\n",
       "Gmt time                                                           \n",
       "2016-07-08 00:00:00  1.10634  1.10815  1.10622  1.10814  17745.2401\n",
       "2016-07-08 04:00:00  1.10816  1.10899  1.10722  1.10764  28404.7499\n",
       "2016-07-08 08:00:00  1.10764  1.10811  1.10572  1.10627  37149.1504\n",
       "2016-07-08 12:00:00  1.10626  1.11201  1.10018  1.10360  78897.1592\n",
       "2016-07-08 16:00:00  1.10361  1.10594  1.10352  1.10515  26419.8901"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_window.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image files\n",
    "Don't run this section if images are already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plots for individual candlesticks in window\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (0.4, 0.8)\n",
    "\n",
    "for i in range(len(df_window)):\n",
    "    try:\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.rcParams['figure.figsize'] = (0.4, 0.8)\n",
    "        to_plot = df_window[i:i+1]\n",
    "        finplt.candlestick2_ohlc(ax, to_plot.Open, to_plot.High, to_plot.Low, to_plot.Close,\n",
    "                             width=0.6, colorup='g', colordown='r', alpha=1)\n",
    "        plt.axis('off')\n",
    "        plt.savefig('./candles/' + str(df_window.iloc[i].name)[:-6] + 'h.jpg')\n",
    "        plt.close()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert plots to greyscale and Keras-ready\n",
    "\n",
    "files = listdir('./candles/')\n",
    "files.sort()\n",
    "\n",
    "for file in files:\n",
    "    i = Image.open('./candles/' + file).convert('L')\n",
    "    j = np.asarray(i.getdata(), dtype=np.float64).reshape((i.size[1], i.size[0]))\n",
    "    j = np.asarray(j, dtype=np.uint8) #if values still in range 0-255! \n",
    "    img = Image.fromarray(j, mode='L')\n",
    "    img.save('./candles/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us have a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 28, 57, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and preprocess X multi-dimentional array of all images\n",
    "\n",
    "files = listdir('./candles/')\n",
    "files.sort()\n",
    "\n",
    "X = [[] for _ in range(len(files))]\n",
    "for i, file in enumerate(files):\n",
    "    X[i].append(np.array(Image.open('./candles/' + file)))\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.astype('float32')\n",
    "X /= 255\n",
    "\n",
    "X = X.reshape(X.shape[0], 28, 57, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X[:35]\n",
    "#y_train = y[:35]\n",
    "#X_test = X[35:]\n",
    "#y_test = y[35:]\n",
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no good? use more advanced CNN model following below\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(28, 57, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=25, verbose=1)\n",
    "\n",
    "#score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "603/603 [==============================] - 4s 7ms/step - loss: 1.3800 - acc: 0.6202\n",
      "Epoch 2/25\n",
      "603/603 [==============================] - 3s 6ms/step - loss: 1.1528 - acc: 0.6567\n",
      "Epoch 3/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.7454 - acc: 0.7363\n",
      "Epoch 4/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.4468 - acc: 0.8308\n",
      "Epoch 5/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.4228 - acc: 0.8408\n",
      "Epoch 6/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.3327 - acc: 0.8806\n",
      "Epoch 7/25\n",
      "603/603 [==============================] - 3s 6ms/step - loss: 0.2966 - acc: 0.8823\n",
      "Epoch 8/25\n",
      "603/603 [==============================] - 4s 6ms/step - loss: 0.2702 - acc: 0.9022\n",
      "Epoch 9/25\n",
      "603/603 [==============================] - 4s 6ms/step - loss: 0.2404 - acc: 0.9104\n",
      "Epoch 10/25\n",
      "603/603 [==============================] - 4s 6ms/step - loss: 0.2294 - acc: 0.9088\n",
      "Epoch 11/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.2127 - acc: 0.9187\n",
      "Epoch 12/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.2040 - acc: 0.9221\n",
      "Epoch 13/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1897 - acc: 0.9237\n",
      "Epoch 14/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1972 - acc: 0.9071\n",
      "Epoch 15/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1924 - acc: 0.9287\n",
      "Epoch 16/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1870 - acc: 0.9187\n",
      "Epoch 17/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1679 - acc: 0.9353\n",
      "Epoch 18/25\n",
      "603/603 [==============================] - 3s 6ms/step - loss: 0.2065 - acc: 0.9187\n",
      "Epoch 19/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.2010 - acc: 0.9204\n",
      "Epoch 20/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1786 - acc: 0.9204\n",
      "Epoch 21/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1721 - acc: 0.9353\n",
      "Epoch 22/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1282 - acc: 0.9519\n",
      "Epoch 23/25\n",
      "603/603 [==============================] - 3s 5ms/step - loss: 0.1438 - acc: 0.9386\n",
      "Epoch 24/25\n",
      "603/603 [==============================] - 3s 6ms/step - loss: 0.1269 - acc: 0.9502\n",
      "Epoch 25/25\n",
      "603/603 [==============================] - 3s 6ms/step - loss: 0.1296 - acc: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9b9d15e48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', input_shape=(28, 57, 1), padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='linear', padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='linear', padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories:\n",
    "```\n",
    "0: \"No category\"\n",
    "1: \"Hammer with body near high\",\n",
    "2: \"Hammer with body near low\",\n",
    "3: \"Spinning top\",\n",
    "4: \"Doji with close near high\",\n",
    "5: \"Doji with close near low\",\n",
    "6: \"Doji with close near middle\",\n",
    "7: \"Marubozu\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ey = model.predict(X)\n",
    "predictions = np.empty(0).astype(int)\n",
    "tol = 0.45\n",
    "\n",
    "for i, e in enumerate(ey):\n",
    "    if e[1] >= tol or e[2] >= tol or e[3] >= tol or e[4] >= tol or e[5] >= tol or e[6] >= tol or e[7] >= tol:\n",
    "        print(str(i) + ': ' + str(np.apply_along_axis(lambda e: np.round(e, 2), 0, ey[i])))\n",
    "        predictions = np.append(predictions, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predictions:\n",
    "    print(str(p) + ': ' + str(y[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actuals = []\n",
    "for i, yy in enumerate(y):\n",
    "    if yy[1] == 1 or yy[2] == 1 or yy[3] == 1 or yy[4] == 1 or yy[5] == 1 or yy[6] == 1:\n",
    "        print(str(i) + ': ' + str(yy))\n",
    "        actuals = np.append(actuals, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(actuals)):\n",
    "    if predictions[i] != actuals[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a test split, define bigger X_test set from df, and generate images for them. Predict their shape, and save images with text of what is predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338, 28, 57, 1)\n"
     ]
    }
   ],
   "source": [
    "df_test = df.iloc[1000:1200, :]\n",
    "\n",
    "# Save plots for individual candlesticks in window\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (0.4, 0.8)\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    try:\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.rcParams['figure.figsize'] = (0.4, 0.8)\n",
    "        to_plot = df_test[i:i+1]\n",
    "        finplt.candlestick2_ohlc(ax, to_plot.Open, to_plot.High, to_plot.Low, to_plot.Close,\n",
    "                             width=0.6, colorup='g', colordown='r', alpha=1)\n",
    "        plt.axis('off')\n",
    "        plt.savefig('./test/' + str(df_test.iloc[i].name)[:-6] + 'h.jpg')\n",
    "        plt.close()\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "test_files = listdir('./test/')\n",
    "test_files.sort()\n",
    "\n",
    "# Convert plots to greyscale and Keras-ready\n",
    "\n",
    "for file in test_files:\n",
    "    i = Image.open('./test/' + file).convert('L')\n",
    "    j = np.asarray(i.getdata(), dtype=np.float64).reshape((i.size[1], i.size[0]))\n",
    "    j = np.asarray(j, dtype=np.uint8) #if values still in range 0-255! \n",
    "    img = Image.fromarray(j, mode='L')\n",
    "    img.save('./test/' + file)\n",
    "    \n",
    "# Define and preprocess X multi-dimentional array of all images\n",
    "\n",
    "X_test = [[] for _ in range(len(test_files))]\n",
    "for i, file in enumerate(test_files):\n",
    "    X_test[i].append(np.array(Image.open('./test/' + file)))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 57, 1)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = {1: 'Hammer with body near high', 2: 'Hammer with body near low', 3: 'Spinning top',\n",
    "       4: 'Doji with close near high', 5: 'Doji with close near low', 6: 'Doji with close near middle',\n",
    "       7: 'Marubozu', 0: 'No category'}\n",
    "\n",
    "text = []\n",
    "for i in range(len(y_test)):\n",
    "    pred = cat[np.argmax(y_test[i])]\n",
    "    text = np.append(text, pred)\n",
    "\n",
    "for f, file in enumerate(test_files):\n",
    "    i = Image.open('./test/' + file)\n",
    "    j = Image.fromarray(np.full((200, 193), 255, dtype='uint8'))\n",
    "    \n",
    "    basewidth=95\n",
    "    wpercent = (basewidth/float(i.size[0]))\n",
    "    hsize = int((float(i.size[1])*float(wpercent)))\n",
    "    i = i.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    j.paste(i, (0,0))\n",
    "    \n",
    "    draw = ImageDraw.Draw(j)\n",
    "    draw.text((0, 0), text[f], (0), ImageFont.truetype(\"font.ttf\", 14))\n",
    "    j.save('./test_result/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(y_test):\n",
    "    if e[1] >= tol or e[2] >= tol or e[3] >= tol or e[4] >= tol or e[5] >= tol or e[6] >= tol:\n",
    "        print(str(i) + ': ' + str(np.apply_along_axis(lambda e: np.round(e, 2), 0, y_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dat model\n",
    "For loading, use\n",
    "```\n",
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'An eye for an eye - a CNN model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
